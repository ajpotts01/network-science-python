{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import spacy\n",
    "from spacy import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp: Language = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHR_SPACE: str = \" \"\n",
    "CHR_APOST: str = \"창\\x80\\x99\"  # '\n",
    "CHR_SDQUOT: str = \"창\\x80\\x9c\" # \"\n",
    "CHR_DDQUOT: str = \"창\\x80\\x9d\" # \"\"\n",
    "CHR_MISC: str = \"창\\x80\\x94\"   # Not sure what this is but it gets replaced by a space\n",
    "\n",
    "def get_data(url: str) -> str:\n",
    "    text_output: str = requests.get(url=url).text\n",
    "    return text_output\n",
    "\n",
    "def clean_data(text_input: str, start_text: str, end_text: str=\"THE END\") -> str:\n",
    "    index_start: int = text_input.index(start_text)\n",
    "    index_end: int = text_input.rindex(end_text)\n",
    "    text_output: str = (\n",
    "        text_input[index_start:index_end]\n",
    "        .replace(\"\\r\", CHR_SPACE)\n",
    "        .replace(\"\\n\", CHR_SPACE)\n",
    "        .replace(CHR_APOST, \"'\")\n",
    "        .replace(CHR_SDQUOT, '\"') # lol\n",
    "        .replace(CHR_DDQUOT, '\"') # The book replaces this char with \"\" so that thoughts and dialog plus \"he said\" etc. get captured as one sentence\n",
    "        .replace(CHR_MISC, CHR_SPACE)\n",
    "    )\n",
    "\n",
    "    return text_output\n",
    "\n",
    "def remove_char_from_entity(text_entity: str, char_to_remove: str) -> str:\n",
    "    if char_to_remove in text_entity:\n",
    "        start_index: int = text_entity.index(char_to_remove)\n",
    "        text_entity_cleaned: str = text_entity[:start_index]\n",
    "        return text_entity_cleaned\n",
    "\n",
    "    return text_entity\n",
    "\n",
    "def clean_entity(text_entity: str) -> str:\n",
    "    text_output: str = text_entity.strip()\n",
    "    text_output = remove_char_from_entity(text_entity=text_output, char_to_remove=\"'s\")\n",
    "\n",
    "    return text_output\n",
    "\n",
    "def extract_entities_from_sentence(sentence: spacy.tokens.span.Span, desired_tags: list[str]) -> list[str]:\n",
    "    sentence_doc = nlp(sentence.text)\n",
    "\n",
    "    entities: list[str] = [clean_entity(next_entity.text) for next_entity in sentence_doc.ents if next_entity.label_ in desired_tags]\n",
    "    entities = list(filter(lambda x: x != \"\", entities))\n",
    "\n",
    "    return list(set(entities))\n",
    "\n",
    "def extract_entities(sentences_input: list[str], desired_tags: list[str]) -> list[str]:\n",
    "    # Filtered on desired_tag\n",
    "    \n",
    "    entities: list[str] = [extract_entities_from_sentence(sentence=next_sentence, desired_tags=desired_tags) for next_sentence in sentences_input]\n",
    "    \n",
    "    entities = list(filter(lambda x: len(x) > 1, entities))\n",
    "\n",
    "    return entities\n",
    "\n",
    "def get_book_entities(url_book: str, start_text: str, end_text: str=\"THE END\") -> list[str]:\n",
    "    # Step 1: Get book data\n",
    "    text_book: str = get_data(url=url_book)\n",
    "    text_cleaned: str = clean_data(text_input=text_book, start_text=start_text, end_text=end_text)\n",
    "\n",
    "    doc = nlp(text=text_cleaned)\n",
    "\n",
    "    # Step 2: Get tags\n",
    "    sentences: list[str] = list(doc.sents)\n",
    "\n",
    "    entities: list[list[str]] = extract_entities(sentences_input=sentences, desired_tags=[\"PERSON\", \"ORG\", \"GPE\"])\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_metamorphosis: str = \"https://www.gutenberg.org/files/5200/5200-0.txt\"\n",
    "entities_metamorphosis: list[list[str]] = get_book_entities(url_book=url_metamorphosis, start_text=\"One moring\", end_text=\"*** END OF THE PROJECT GUTENBERG EBOOK METAMORPHOSIS ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Grete', 'Gregor'],\n",
       " ['Grete', 'Gregor'],\n",
       " ['fro', 'Gregor'],\n",
       " ['Grete', 'Gregor'],\n",
       " ['Grete', 'Gregor'],\n",
       " ['Grete', 'Gregor'],\n",
       " ['Grete', 'Gregor'],\n",
       " ['Grete', 'Gregor'],\n",
       " ['Gregor', 'jaws'],\n",
       " ['Gregor', 'Samsa'],\n",
       " ['Gregor', 'Samsa'],\n",
       " ['Grete', 'Samsa'],\n",
       " ['Grete', 'Samsa'],\n",
       " ['Grete', 'Samsa']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_metamorphosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_dk(text: str):\n",
    "    doc = nlp(text)\n",
    "    sentences = list(doc.sents)\n",
    "    entities = []\n",
    "    for sentence in sentences:\n",
    "        sentence_entities = []\n",
    "        sent_doc = nlp(sentence.text)\n",
    "        for ent in sent_doc.ents:\n",
    "            if ent.label_ in ['PERSON', 'ORG', 'GPE']:\n",
    "                entity = ent.text.strip()\n",
    "                if \"'s\" in entity:\n",
    "                    cutoff = entity.index(\"'s\")\n",
    "                    entity = entity[:cutoff]\n",
    "                if entity != '':\n",
    "                    sentence_entities.append(entity)\n",
    "        sentence_entities = list(set(sentence_entities))\n",
    "        if len(sentence_entities) > 1:\n",
    "            entities.append(sentence_entities)\n",
    "    return entities\n",
    "\n",
    "def get_book_entities_dk(url_book: str, start_text: str, end_text: str) -> list[str]:\n",
    "    # Step 1: Get book data\n",
    "    text_book: str = get_data(url=url_book)\n",
    "    text_cleaned: str = clean_data(text_input=text_book, start_text=start_text, end_text=end_text)\n",
    "\n",
    "    entities: list[list[str]] = extract_entities_dk(text=text_cleaned)\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check against the book - the book lists different output to what the copy-pasted code does, but same as the code written above\n",
    "# This is likely a difference in spaCy lib/model versions.\n",
    "entities_dk: list[list[str]] = get_book_entities_dk(url_book=url_metamorphosis, start_text=\"One morning\", end_text=\"*** END OF THE PROJECT GUTENBERG EBOOK METAMORPHOSIS ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Grete', 'Gregor'],\n",
       " ['Grete', 'Gregor'],\n",
       " ['fro', 'Gregor'],\n",
       " ['Grete', 'Gregor'],\n",
       " ['Grete', 'Gregor'],\n",
       " ['Grete', 'Gregor'],\n",
       " ['Grete', 'Gregor'],\n",
       " ['Grete', 'Gregor'],\n",
       " ['Gregor', 'jaws'],\n",
       " ['Gregor', 'Samsa'],\n",
       " ['Gregor', 'Samsa'],\n",
       " ['Grete', 'Samsa'],\n",
       " ['Grete', 'Samsa'],\n",
       " ['Grete', 'Samsa']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_dk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ajp_vs_dk_entities(ent_ajp: list[list[str]], ent_dk: list[list[str]]):\n",
    "    overall_match: bool = True\n",
    "\n",
    "    assert len(ent_ajp) == len(ent_dk)\n",
    "    for next_index in range(len(ent_ajp)):\n",
    "        print(f\"{ent_ajp[next_index]=}\")\n",
    "        print(f\"{ent_dk[next_index]=}\")\n",
    "        current_match = ent_dk[next_index] == ent_ajp[next_index]\n",
    "        print(f\"Match: {current_match}\")\n",
    "        overall_match = overall_match and current_match\n",
    "\n",
    "    print(f\"Overall match: {overall_match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ent_ajp[next_index]=['Grete', 'Gregor']\n",
      "ent_dk[next_index]=['Grete', 'Gregor']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Grete', 'Gregor']\n",
      "ent_dk[next_index]=['Grete', 'Gregor']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['fro', 'Gregor']\n",
      "ent_dk[next_index]=['fro', 'Gregor']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Grete', 'Gregor']\n",
      "ent_dk[next_index]=['Grete', 'Gregor']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Grete', 'Gregor']\n",
      "ent_dk[next_index]=['Grete', 'Gregor']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Grete', 'Gregor']\n",
      "ent_dk[next_index]=['Grete', 'Gregor']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Grete', 'Gregor']\n",
      "ent_dk[next_index]=['Grete', 'Gregor']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Grete', 'Gregor']\n",
      "ent_dk[next_index]=['Grete', 'Gregor']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Gregor', 'jaws']\n",
      "ent_dk[next_index]=['Gregor', 'jaws']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Gregor', 'Samsa']\n",
      "ent_dk[next_index]=['Gregor', 'Samsa']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Gregor', 'Samsa']\n",
      "ent_dk[next_index]=['Gregor', 'Samsa']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Grete', 'Samsa']\n",
      "ent_dk[next_index]=['Grete', 'Samsa']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Grete', 'Samsa']\n",
      "ent_dk[next_index]=['Grete', 'Samsa']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Grete', 'Samsa']\n",
      "ent_dk[next_index]=['Grete', 'Samsa']\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "test_ajp_vs_dk_entities(entities_metamorphosis, entities_dk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_alice: str = \"https://www.gutenberg.org/files/11/11-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['New Zealand', 'Australia'],\n",
       " ['Hearthrug', 'Alice'],\n",
       " ['Ada', 'Mabel'],\n",
       " ['Rome', 'Paris', 'London'],\n",
       " ['Alice', 'Mabel'],\n",
       " ['William the Conqueror', 'Alice'],\n",
       " ['Mouse', 'Alice'],\n",
       " ['Mouse', 'Alice'],\n",
       " ['Mouse', 'Alice'],\n",
       " ['Northumbria', 'Mercia', 'Edwin', 'Morcar'],\n",
       " ['Morcar', 'Mercia', 'Canterbury', 'Northumbria', 'Stigand'],\n",
       " ['Mouse', '창\\x80\\x98it'],\n",
       " ['Mouse', 'Edgar', 'William'],\n",
       " ['Normans', 'Alice'],\n",
       " ['Mouse', 'Alice'],\n",
       " ['Mouse', 'Alice'],\n",
       " ['Mouse', 'Fury', '창\\x80\\x98Let'],\n",
       " ['Mouse', 'Alice'],\n",
       " ['Mouse', 'Alice'],\n",
       " ['Dinah', 'Alice'],\n",
       " ['Mary Ann', 'Alice'],\n",
       " ['Bill', 'Alice'],\n",
       " ['Bill', 'Alice'],\n",
       " ['Caterpillar', 'Alice'],\n",
       " ['Caterpillar', 'Alice'],\n",
       " ['Caterpillar', 'Alice'],\n",
       " ['Caterpillar', 'William_'],\n",
       " ['William', 'Alice'],\n",
       " ['Caterpillar', 'Alice'],\n",
       " ['Alice', 'Pigeon'],\n",
       " ['Fish-Footman', 'Alice'],\n",
       " ['Alice', 'Cheshire'],\n",
       " ['CHORUS', 'Alice'],\n",
       " ['Duchess', 'Alice'],\n",
       " ['Hare', 'Hatter'],\n",
       " ['Hare', 'Alice'],\n",
       " ['Hare', 'Hatter', 'Dormouse'],\n",
       " ['Alice', 'Dormouse'],\n",
       " ['Hatter', 'Alice'],\n",
       " ['Hatter', 'Alice'],\n",
       " ['Hatter', 'Dormouse'],\n",
       " ['Hatter', 'Alice'],\n",
       " ['Hatter', 'Alice'],\n",
       " ['Hatter', 'Time'],\n",
       " ['Hatter', 'Alice'],\n",
       " ['Hare', 'the Queen of Hearts'],\n",
       " ['Hatter', '창\\x80\\x98Up'],\n",
       " ['Hatter', '창\\x80\\x98He', 'Queen'],\n",
       " ['Elsie', 'Tillie', 'Lacie', 'Alice', 'Dormouse'],\n",
       " ['Hare', 'Alice'],\n",
       " ['Alice', 'Dormouse'],\n",
       " ['Hare', 'Hatter', 'Alice', 'Dormouse'],\n",
       " ['Hare', 'Alice', 'Dormouse'],\n",
       " ['Hare', 'Hatter', 'Alice'],\n",
       " ['Alice', 'Dormouse'],\n",
       " ['Hatter', 'Alice', 'Dormouse'],\n",
       " ['Alice', 'Dormouse'],\n",
       " ['Alice', 'Dormouse'],\n",
       " ['Hatter', 'Alice', 'Dormouse'],\n",
       " ['Alice', 'Dormouse'],\n",
       " ['Miss', 'Queen'],\n",
       " ['Kings', 'Queens', 'Alice'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Duchess', 'Alice'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Arithmetic Ambition', 'Derision', 'Uglification'],\n",
       " ['Stretching', 'Alice'],\n",
       " ['Lobster Quadrille', 'Alice'],\n",
       " ['France', 'England'],\n",
       " ['Alice', '창\\x80\\x98purpose'],\n",
       " ['Caterpillar', 'William_'],\n",
       " ['Panther', 'Alice'],\n",
       " ['Gryphon', 'Alice'],\n",
       " ['Gryphon', 'Alice'],\n",
       " ['Hare', 'Hatter', 'Dormouse'],\n",
       " ['Hatter', 'Queen'],\n",
       " ['Hatter', 'Dormouse', 'Queen'],\n",
       " ['Hare', 'Hatter'],\n",
       " ['Hatter', 'Dormouse'],\n",
       " ['Hatter', 'Dormouse'],\n",
       " ['Hatter', 'Queen'],\n",
       " ['Hatter', 'Queen'],\n",
       " ['Adventures', 'Alice'],\n",
       " ['Lizard', 'Duchess', 'Hare', 'Queen', 'Mouse'],\n",
       " ['Wonderland', 'Turtle', 'Queen']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_alice: list[list[str]] = get_book_entities(url_book=url_alice, start_text=\"Alice was beginning\", end_text=\"THE END\")\n",
    "entities_alice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['New Zealand', 'Australia'],\n",
       " ['Hearthrug', 'Alice'],\n",
       " ['Ada', 'Mabel'],\n",
       " ['Rome', 'Paris', 'London'],\n",
       " ['Alice', 'Mabel'],\n",
       " ['William the Conqueror', 'Alice'],\n",
       " ['Mouse', 'Alice'],\n",
       " ['Mouse', 'Alice'],\n",
       " ['Mouse', 'Alice'],\n",
       " ['Northumbria', 'Mercia', 'Edwin', 'Morcar'],\n",
       " ['Morcar', 'Mercia', 'Canterbury', 'Northumbria', 'Stigand'],\n",
       " ['Mouse', '창\\x80\\x98it'],\n",
       " ['Mouse', 'Edgar', 'William'],\n",
       " ['Normans', 'Alice'],\n",
       " ['Mouse', 'Alice'],\n",
       " ['Mouse', 'Alice'],\n",
       " ['Mouse', 'Fury', '창\\x80\\x98Let'],\n",
       " ['Mouse', 'Alice'],\n",
       " ['Mouse', 'Alice'],\n",
       " ['Dinah', 'Alice'],\n",
       " ['Mary Ann', 'Alice'],\n",
       " ['Bill', 'Alice'],\n",
       " ['Bill', 'Alice'],\n",
       " ['Caterpillar', 'Alice'],\n",
       " ['Caterpillar', 'Alice'],\n",
       " ['Caterpillar', 'Alice'],\n",
       " ['Caterpillar', 'William_'],\n",
       " ['William', 'Alice'],\n",
       " ['Caterpillar', 'Alice'],\n",
       " ['Alice', 'Pigeon'],\n",
       " ['Fish-Footman', 'Alice'],\n",
       " ['Alice', 'Cheshire'],\n",
       " ['CHORUS', 'Alice'],\n",
       " ['Duchess', 'Alice'],\n",
       " ['Hare', 'Hatter'],\n",
       " ['Hare', 'Alice'],\n",
       " ['Hare', 'Hatter', 'Dormouse'],\n",
       " ['Alice', 'Dormouse'],\n",
       " ['Hatter', 'Alice'],\n",
       " ['Hatter', 'Alice'],\n",
       " ['Hatter', 'Dormouse'],\n",
       " ['Hatter', 'Alice'],\n",
       " ['Hatter', 'Alice'],\n",
       " ['Hatter', 'Time'],\n",
       " ['Hatter', 'Alice'],\n",
       " ['Hare', 'the Queen of Hearts'],\n",
       " ['Hatter', '창\\x80\\x98Up'],\n",
       " ['Hatter', '창\\x80\\x98He', 'Queen'],\n",
       " ['Elsie', 'Tillie', 'Lacie', 'Alice', 'Dormouse'],\n",
       " ['Hare', 'Alice'],\n",
       " ['Alice', 'Dormouse'],\n",
       " ['Hare', 'Hatter', 'Alice', 'Dormouse'],\n",
       " ['Hare', 'Alice', 'Dormouse'],\n",
       " ['Hare', 'Hatter', 'Alice'],\n",
       " ['Alice', 'Dormouse'],\n",
       " ['Hatter', 'Alice', 'Dormouse'],\n",
       " ['Alice', 'Dormouse'],\n",
       " ['Alice', 'Dormouse'],\n",
       " ['Hatter', 'Alice', 'Dormouse'],\n",
       " ['Alice', 'Dormouse'],\n",
       " ['Miss', 'Queen'],\n",
       " ['Kings', 'Queens', 'Alice'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Duchess', 'Alice'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Alice', 'Queen'],\n",
       " ['Arithmetic Ambition', 'Derision', 'Uglification'],\n",
       " ['Stretching', 'Alice'],\n",
       " ['Lobster Quadrille', 'Alice'],\n",
       " ['France', 'England'],\n",
       " ['Alice', '창\\x80\\x98purpose'],\n",
       " ['Caterpillar', 'William_'],\n",
       " ['Panther', 'Alice'],\n",
       " ['Gryphon', 'Alice'],\n",
       " ['Gryphon', 'Alice'],\n",
       " ['Hare', 'Hatter', 'Dormouse'],\n",
       " ['Hatter', 'Queen'],\n",
       " ['Hatter', 'Dormouse', 'Queen'],\n",
       " ['Hare', 'Hatter'],\n",
       " ['Hatter', 'Dormouse'],\n",
       " ['Hatter', 'Dormouse'],\n",
       " ['Hatter', 'Queen'],\n",
       " ['Hatter', 'Queen'],\n",
       " ['Adventures', 'Alice'],\n",
       " ['Lizard', 'Duchess', 'Hare', 'Queen', 'Mouse'],\n",
       " ['Wonderland', 'Turtle', 'Queen']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_alice_dk: list[list[str]] = get_book_entities_dk(url_book=url_alice, start_text=\"Alice was beginning\", end_text=\"THE END\")\n",
    "entities_alice_dk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ent_ajp[next_index]=['New Zealand', 'Australia']\n",
      "ent_dk[next_index]=['New Zealand', 'Australia']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hearthrug', 'Alice']\n",
      "ent_dk[next_index]=['Hearthrug', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Ada', 'Mabel']\n",
      "ent_dk[next_index]=['Ada', 'Mabel']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Rome', 'Paris', 'London']\n",
      "ent_dk[next_index]=['Rome', 'Paris', 'London']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Mabel']\n",
      "ent_dk[next_index]=['Alice', 'Mabel']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['William the Conqueror', 'Alice']\n",
      "ent_dk[next_index]=['William the Conqueror', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Mouse', 'Alice']\n",
      "ent_dk[next_index]=['Mouse', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Mouse', 'Alice']\n",
      "ent_dk[next_index]=['Mouse', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Mouse', 'Alice']\n",
      "ent_dk[next_index]=['Mouse', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Northumbria', 'Mercia', 'Edwin', 'Morcar']\n",
      "ent_dk[next_index]=['Northumbria', 'Mercia', 'Edwin', 'Morcar']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Morcar', 'Mercia', 'Canterbury', 'Northumbria', 'Stigand']\n",
      "ent_dk[next_index]=['Morcar', 'Mercia', 'Canterbury', 'Northumbria', 'Stigand']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Mouse', '창\\x80\\x98it']\n",
      "ent_dk[next_index]=['Mouse', '창\\x80\\x98it']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Mouse', 'Edgar', 'William']\n",
      "ent_dk[next_index]=['Mouse', 'Edgar', 'William']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Normans', 'Alice']\n",
      "ent_dk[next_index]=['Normans', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Mouse', 'Alice']\n",
      "ent_dk[next_index]=['Mouse', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Mouse', 'Alice']\n",
      "ent_dk[next_index]=['Mouse', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Mouse', 'Fury', '창\\x80\\x98Let']\n",
      "ent_dk[next_index]=['Mouse', 'Fury', '창\\x80\\x98Let']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Mouse', 'Alice']\n",
      "ent_dk[next_index]=['Mouse', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Mouse', 'Alice']\n",
      "ent_dk[next_index]=['Mouse', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Dinah', 'Alice']\n",
      "ent_dk[next_index]=['Dinah', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Mary Ann', 'Alice']\n",
      "ent_dk[next_index]=['Mary Ann', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Bill', 'Alice']\n",
      "ent_dk[next_index]=['Bill', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Bill', 'Alice']\n",
      "ent_dk[next_index]=['Bill', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Caterpillar', 'Alice']\n",
      "ent_dk[next_index]=['Caterpillar', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Caterpillar', 'Alice']\n",
      "ent_dk[next_index]=['Caterpillar', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Caterpillar', 'Alice']\n",
      "ent_dk[next_index]=['Caterpillar', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Caterpillar', 'William_']\n",
      "ent_dk[next_index]=['Caterpillar', 'William_']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['William', 'Alice']\n",
      "ent_dk[next_index]=['William', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Caterpillar', 'Alice']\n",
      "ent_dk[next_index]=['Caterpillar', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Pigeon']\n",
      "ent_dk[next_index]=['Alice', 'Pigeon']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Fish-Footman', 'Alice']\n",
      "ent_dk[next_index]=['Fish-Footman', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Cheshire']\n",
      "ent_dk[next_index]=['Alice', 'Cheshire']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['CHORUS', 'Alice']\n",
      "ent_dk[next_index]=['CHORUS', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Duchess', 'Alice']\n",
      "ent_dk[next_index]=['Duchess', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hare', 'Hatter']\n",
      "ent_dk[next_index]=['Hare', 'Hatter']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hare', 'Alice']\n",
      "ent_dk[next_index]=['Hare', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hare', 'Hatter', 'Dormouse']\n",
      "ent_dk[next_index]=['Hare', 'Hatter', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Dormouse']\n",
      "ent_dk[next_index]=['Alice', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Alice']\n",
      "ent_dk[next_index]=['Hatter', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Alice']\n",
      "ent_dk[next_index]=['Hatter', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Dormouse']\n",
      "ent_dk[next_index]=['Hatter', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Alice']\n",
      "ent_dk[next_index]=['Hatter', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Alice']\n",
      "ent_dk[next_index]=['Hatter', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Time']\n",
      "ent_dk[next_index]=['Hatter', 'Time']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Alice']\n",
      "ent_dk[next_index]=['Hatter', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hare', 'the Queen of Hearts']\n",
      "ent_dk[next_index]=['Hare', 'the Queen of Hearts']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', '창\\x80\\x98Up']\n",
      "ent_dk[next_index]=['Hatter', '창\\x80\\x98Up']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', '창\\x80\\x98He', 'Queen']\n",
      "ent_dk[next_index]=['Hatter', '창\\x80\\x98He', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Elsie', 'Tillie', 'Lacie', 'Alice', 'Dormouse']\n",
      "ent_dk[next_index]=['Elsie', 'Tillie', 'Lacie', 'Alice', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hare', 'Alice']\n",
      "ent_dk[next_index]=['Hare', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Dormouse']\n",
      "ent_dk[next_index]=['Alice', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hare', 'Hatter', 'Alice', 'Dormouse']\n",
      "ent_dk[next_index]=['Hare', 'Hatter', 'Alice', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hare', 'Alice', 'Dormouse']\n",
      "ent_dk[next_index]=['Hare', 'Alice', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hare', 'Hatter', 'Alice']\n",
      "ent_dk[next_index]=['Hare', 'Hatter', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Dormouse']\n",
      "ent_dk[next_index]=['Alice', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Alice', 'Dormouse']\n",
      "ent_dk[next_index]=['Hatter', 'Alice', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Dormouse']\n",
      "ent_dk[next_index]=['Alice', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Dormouse']\n",
      "ent_dk[next_index]=['Alice', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Alice', 'Dormouse']\n",
      "ent_dk[next_index]=['Hatter', 'Alice', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Dormouse']\n",
      "ent_dk[next_index]=['Alice', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Miss', 'Queen']\n",
      "ent_dk[next_index]=['Miss', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Kings', 'Queens', 'Alice']\n",
      "ent_dk[next_index]=['Kings', 'Queens', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Queen']\n",
      "ent_dk[next_index]=['Alice', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Queen']\n",
      "ent_dk[next_index]=['Alice', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Queen']\n",
      "ent_dk[next_index]=['Alice', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Queen']\n",
      "ent_dk[next_index]=['Alice', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Queen']\n",
      "ent_dk[next_index]=['Alice', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Queen']\n",
      "ent_dk[next_index]=['Alice', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Queen']\n",
      "ent_dk[next_index]=['Alice', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Duchess', 'Alice']\n",
      "ent_dk[next_index]=['Duchess', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Queen']\n",
      "ent_dk[next_index]=['Alice', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Queen']\n",
      "ent_dk[next_index]=['Alice', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Queen']\n",
      "ent_dk[next_index]=['Alice', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Queen']\n",
      "ent_dk[next_index]=['Alice', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Queen']\n",
      "ent_dk[next_index]=['Alice', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', 'Queen']\n",
      "ent_dk[next_index]=['Alice', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Arithmetic Ambition', 'Derision', 'Uglification']\n",
      "ent_dk[next_index]=['Arithmetic Ambition', 'Derision', 'Uglification']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Stretching', 'Alice']\n",
      "ent_dk[next_index]=['Stretching', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Lobster Quadrille', 'Alice']\n",
      "ent_dk[next_index]=['Lobster Quadrille', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['France', 'England']\n",
      "ent_dk[next_index]=['France', 'England']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Alice', '창\\x80\\x98purpose']\n",
      "ent_dk[next_index]=['Alice', '창\\x80\\x98purpose']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Caterpillar', 'William_']\n",
      "ent_dk[next_index]=['Caterpillar', 'William_']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Panther', 'Alice']\n",
      "ent_dk[next_index]=['Panther', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Gryphon', 'Alice']\n",
      "ent_dk[next_index]=['Gryphon', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Gryphon', 'Alice']\n",
      "ent_dk[next_index]=['Gryphon', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hare', 'Hatter', 'Dormouse']\n",
      "ent_dk[next_index]=['Hare', 'Hatter', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Queen']\n",
      "ent_dk[next_index]=['Hatter', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Dormouse', 'Queen']\n",
      "ent_dk[next_index]=['Hatter', 'Dormouse', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hare', 'Hatter']\n",
      "ent_dk[next_index]=['Hare', 'Hatter']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Dormouse']\n",
      "ent_dk[next_index]=['Hatter', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Dormouse']\n",
      "ent_dk[next_index]=['Hatter', 'Dormouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Queen']\n",
      "ent_dk[next_index]=['Hatter', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Hatter', 'Queen']\n",
      "ent_dk[next_index]=['Hatter', 'Queen']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Adventures', 'Alice']\n",
      "ent_dk[next_index]=['Adventures', 'Alice']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Lizard', 'Duchess', 'Hare', 'Queen', 'Mouse']\n",
      "ent_dk[next_index]=['Lizard', 'Duchess', 'Hare', 'Queen', 'Mouse']\n",
      "Match: True\n",
      "ent_ajp[next_index]=['Wonderland', 'Turtle', 'Queen']\n",
      "ent_dk[next_index]=['Wonderland', 'Turtle', 'Queen']\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "test_ajp_vs_dk_entities(entities_alice, entities_alice_dk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
